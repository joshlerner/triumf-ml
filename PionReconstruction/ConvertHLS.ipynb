{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "280c83d0-8579-4df4-bb2e-ec895d8afcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "149be721-3a32-40e9-a9d2-204abb0455d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"6\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['PATH'] = os.environ['XILINX_VIVADO'] + '/bin:' + os.environ['PATH']\n",
    "#RUN BEFORE#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c871e0-75fa-4ac2-ac31-252568e255b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joshualerner/projects/src/hls4ml/hls4ml/converters/__init__.py:25: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\", stacklevel=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to import handlers from core.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from convolution.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from reshape.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from pooling.py: No module named 'torch'.\n",
      "WARNING: Failed to import handlers from merge.py: No module named 'torch'.\n"
     ]
    }
   ],
   "source": [
    "#RUN AFTER#\n",
    "\n",
    "import hls4ml\n",
    "import pickle\n",
    "from time import time\n",
    "\n",
    "from PionReconstruction.util.Models import *\n",
    "from PionReconstruction.util.Generators import *\n",
    "from PionReconstruction.util.Plotting import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4f2afff-5ecf-42a9-b1fb-3cc2cf522abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path = '/fast_scratch_1/atlas_images/v01-45/'\n",
    "\n",
    "cell_geo_path = data_path + 'cell_geo.root'\n",
    "\n",
    "out_path = '/fast_scratch_1/jlerner/data/'\n",
    "\n",
    "norm = 'log' # 'log', 'std', or 'max'\n",
    "scaler = None\n",
    "vmax = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8fd7063-b4b6-4ef7-a63e-6821b408a1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 15:11:43.495023: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-08-02 15:11:43.495120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9389 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b1:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.models.load_model(out_path + f'models/qGarNet_{norm}_{vmax}')\n",
    "\n",
    "with open(out_path + f'models/qGarNet_{norm}_{vmax}/history.pickle', \"rb\") as file:\n",
    "    history = pickle.load(file)\n",
    "\n",
    "if norm == 'std':\n",
    "    with open(out_path + f'models/qGarNet_std_{vmax}/scaler.pickle', 'rb') as file:\n",
    "        scaler = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb481e49-b5a9-4c94-ade3-c1fbd8c6c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'garnet_{norm}_{vmax}'\n",
    "\n",
    "test_file_list = ([[data_path + f'pi0/user.angerami.24559740.OutputStream._000{i:03d}.root', 1] for i in range(232, 264)],\n",
    "                  [[data_path + f'pipm/user.angerami.24559744.OutputStream._000{i:03d}.root', 0] for i in range(232, 264)])\n",
    "\n",
    "test_generator = garnetDataGenerator(test_file_list,\n",
    "                                     cell_geo_path,\n",
    "                                     batch_size=20000,\n",
    "                                     normalizer=(norm, scaler),\n",
    "                                     name=name,\n",
    "                                     labeled=True,\n",
    "                                     preprocess=False,\n",
    "                                     output_dir=out_path + 'test/')\n",
    "\n",
    "x, y = next(test_generator.generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "403a7d64-2a1e-49d2-abc7-b589b36e6a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: data, layer type: InputLayer, input shapes: [[None, 64, 4]], output shape: [None, 64, 4]\n",
      "Layer name: vertex, layer type: InputLayer, input shapes: [[None, 1]], output shape: [None, 1]\n",
      "Layer name: garnet, layer type: GarNetStack, input shapes: [[None, 64, 4], [None, 1]], output shape: [None, 16]\n",
      "Layer name: energy, layer type: InputLayer, input shapes: [[None, 1]], output shape: [None, 1]\n",
      "Layer name: concatenate, layer type: Concatenate, input shapes: [[None, 16], [None, 1]], output shape: [None, 17]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 17]], output shape: [None, 16]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 8]\n",
      "Layer name: classification, layer type: Dense, input shapes: [[None, 8]], output shape: [None, 2]\n",
      "Layer name: regression, layer type: Dense, input shapes: [[None, 8]], output shape: [None, 1]\n"
     ]
    }
   ],
   "source": [
    "config = hls4ml.utils.config_from_keras_model(model, granularity='model')\n",
    "config['Model']['Precision'] = 'ap_fixed<16, 4>'\n",
    "config['LayerName'] = {'input_1': {'Precision': {'result': 'ap_fixed<16, 7, AP_RND, AP_SAT>'}},\n",
    "                       'input_2': {'Precision': {'result': 'ap_uint<16>'}}} # <-- This is the important part\n",
    "\n",
    "config['LayerType'] = {'InputLayer': {'ReuseFactor': 1, 'Trace': False},\n",
    "                       'GarNetStack': {'ReuseFactor': 1, 'Trace': True}, \n",
    "                       'Dense': {'ReuseFactor': 1, 'Trace': True},\n",
    "                       'Activation': {'ReuseFactor': 1, 'Trace': False}}\n",
    "\n",
    "# config['LayerType']['Dense']['Precision'] = {'accum': 'ap_fixed<20,10, AP_RND, AP_SAT>',\n",
    "#                                              'weight': 'ap_fixed<20,10, AP_RND, AP_SAT>',\n",
    "#                                              'bias': 'ap_fixed<20,10, AP_RND, AP_SAT>'}\n",
    "\n",
    "# config['LayerType']['GarNetStack']['Precision'] = {'norm': 'ap_ufixed<16, 4, AP_TRN, AP_SAT>',\n",
    "#                                                    'aggr': 'ap_fixed<22, 10, AP_TRN, AP_SAT>',\n",
    "#                                                    'edge_weight': 'ap_ufixed<12, 0, AP_TRN, AP_SAT>',\n",
    "#                                                    'edge_weight_aggr': 'ap_ufixed<19, 7, AP_TRN, AP_SAT>'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "372417f5-eaca-4533-83d1-449a94175be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {}\n",
    "\n",
    "# config['Model'] = {'ReuseFactor': 1, 'Strategy': 'Latency', 'Precision': 'ap_fixed<18,6>'}\n",
    "\n",
    "# config['LayerType'] = {'InputLayer': {'ReuseFactor': 1, 'Trace': False},\n",
    "#                        'GarNetStack': {'ReuseFactor': 1, 'Trace': True}, \n",
    "#                        'Dense': {'ReuseFactor': 1, 'Trace': True},\n",
    "#                        'Activation': {'ReuseFactor': 1, 'Trace': False}}\n",
    "\n",
    "# config['LayerType']['GarNetStack']['Precision'] = {'default': 'ap_fixed<16, 6, AP_RND, AP_SAT>',\n",
    "#                                                    'result': 'ap_fixed<18, 6, AP_RND, AP_SAT>'}\n",
    "\n",
    "# config['LayerType']['Dense']['Precision'] = {'accum': 'ap_fixed<18, 8>',\n",
    "#                                              'weight': 'ap_fixed<18, 6>',\n",
    "#                                              'result': 'ap_fixed<18, 6, AP_RND, AP_SAT>'}\n",
    "\n",
    "# config['LayerName'] = {'input_1': {'Precision': {'result': 'ap_fixed<14, 5, AP_RND, AP_SAT>'}},\n",
    "#                        'input_2': {'Precision': {'result': 'ap_uint<10>'}},\n",
    "#                        'classification': {'Precision': {'result': 'ap_fixed<16, 6, AP_RND, AP_SAT>'}},\n",
    "#                        'regression': {'Precision': {'result': 'ap_fixed<16, 6, AP_RND, AP_SAT>'}}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "025ce4f5-1a59-4c68-9be1-abac3a87f668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration\n",
      "-----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model': {'Precision': 'ap_fixed<16, 4>',\n",
       "  'ReuseFactor': 1,\n",
       "  'Strategy': 'Latency',\n",
       "  'BramFactor': 1000000000,\n",
       "  'TraceOutput': False},\n",
       " 'LayerName': {'input_1': {'Precision': {'result': 'ap_fixed<16, 7, AP_RND, AP_SAT>'}},\n",
       "  'input_2': {'Precision': {'result': 'ap_uint<16>'}}},\n",
       " 'LayerType': {'InputLayer': {'ReuseFactor': 1, 'Trace': False},\n",
       "  'GarNetStack': {'ReuseFactor': 1, 'Trace': True},\n",
       "  'Dense': {'ReuseFactor': 1, 'Trace': True},\n",
       "  'Activation': {'ReuseFactor': 1, 'Trace': False}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Configuration\")\n",
    "print(\"-----------------------------------\")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db342538-abb8-4464-9812-6797861e29b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: data, layer type: InputLayer, input shapes: [[None, 64, 4]], output shape: [None, 64, 4]\n",
      "Layer name: vertex, layer type: InputLayer, input shapes: [[None, 1]], output shape: [None, 1]\n",
      "Layer name: garnet, layer type: GarNetStack, input shapes: [[None, 64, 4], [None, 1]], output shape: [None, 16]\n",
      "Layer name: energy, layer type: InputLayer, input shapes: [[None, 1]], output shape: [None, 1]\n",
      "Layer name: concatenate, layer type: Concatenate, input shapes: [[None, 16], [None, 1]], output shape: [None, 17]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 17]], output shape: [None, 16]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 8]\n",
      "Layer name: classification, layer type: Dense, input shapes: [[None, 8]], output shape: [None, 2]\n",
      "Layer name: regression, layer type: Dense, input shapes: [[None, 8]], output shape: [None, 1]\n",
      "Creating HLS model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hls_model = hls4ml.converters.convert_from_keras_model(model, hls_config=config, project_name='GarNetHLS',\n",
    "                                                       output_dir='/home/joshualerner/projects/PionReconstruction/data/tmp', \n",
    "                                                       part='xcu250-figd2104-2L-e')#'xcku115-flvb2104-2-i'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2201ca5e-122d-4d46-83bc-0a0ced618a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 15:12:07.025049: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "hls_model.compile()\n",
    "keras_pred = model.predict(x)\n",
    "hls_pred = hls_model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686c087-bb1b-4be4-a8a7-eff733ff4534",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = Plotter(roc, \n",
    "              preds=[keras_pred[0][:,0], hls_pred[0][:,0]],\n",
    "              targets=[y['classification'][:,0], y['classification'][:,0]],\n",
    "              labels=['keras', 'hls'])\n",
    "ROC.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b65a8ce-b641-45fb-84bc-ce25c1217a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if norm == 'log':\n",
    "    keras_scaled_pred = np.exp(keras_pred[-1]*10).reshape(-1,)\n",
    "    hls_scaled_pred = np.exp(hls_pred[-1]*10).reshape(-1,)\n",
    "    scaled_target = np.exp(y['regression']*10).reshape(-1,)\n",
    "elif norm == 'std':\n",
    "    keras_scaled_pred = scaler.inverse_transform(keras_pred[-1]).reshape(-1,)\n",
    "    hls_scaled_pred = scaler.inverse_transform(hls_pred[-1]).reshape(-1,)\n",
    "    scaled_target = scaler.inverse_transform(np.reshape(y['regression'], (-1, 1))).reshape(-1,)\n",
    "elif norm == 'max':\n",
    "    keras_scaled_pred = keras_pred[-1].reshape(-1,) * 2000\n",
    "    hls_scaled_pred = hls_pred[-1].reshape(-1,) * 2000\n",
    "    scaled_target = y['regression'].reshape(-1,) * 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd19a2bb-26f8-4085-8f9e-6f4f59d0f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reg = Plotter(regResponse, \n",
    "              pred=keras_scaled_pred,\n",
    "              target=scaled_target,\n",
    "              stat=['median'],\n",
    "              title='Quantized Keras Model Regression Response')\n",
    "\n",
    "reg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad303a0-6962-4f4f-ab54-1e388f29a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reg = Plotter(regResponse, \n",
    "              pred=hls_scaled_pred,\n",
    "              target=scaled_target,\n",
    "              stat=['median'],\n",
    "              title='Quantized HLS Model Regression Response')\n",
    "\n",
    "reg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de19be5e-caef-408d-9aa8-2f2ad1ccc1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reg = Plotter(regResponseOverlay, \n",
    "              preds=[keras_scaled_pred, hls_scaled_pred], \n",
    "              targets=[scaled_target, scaled_target],\n",
    "              stat=['mean', 'stdmean'],\n",
    "              labels=['keras', 'hls'])\n",
    "reg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbe8ec7-de1e-42f2-8e72-5931bd1c50b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = Plotter(weight_profile, model=model, hls_model=hls_model, x=x)\n",
    "prof.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3055794e-54dd-42ef-82af-e04857106c87",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_start = time\n",
    "hls_model.build(csim=False)\n",
    "print(time - time_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
