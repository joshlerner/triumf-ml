{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6e2698c-8b28-4191-86aa-db41cd73329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9464f8b-7428-4fcb-8dde-92f72d25a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import uproot as ur\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "973a7b67-3a1a-4949-9be5-6e79635a1dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "#RUN BEFORE#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83399097-1891-48d2-a523-897113f197c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RUN AFTER#\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow.keras as keras\n",
    "K = keras.backend\n",
    "\n",
    "from util.Models import *\n",
    "from util.Generators import *\n",
    "from util.Plotting import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "762532cb-f6d9-4dc7-b2e3-f904d7c3abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_path = '/fast_scratch_1/atlas_images/v01-45/'\n",
    "\n",
    "cell_geo_path = data_path + 'cell_geo.root'\n",
    "\n",
    "out_path = '/fast_scratch_1/jlerner/data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f47e42db-533a-4f9c-83aa-5415d4c1379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with ur.open(data_path + 'pi0/user.angerami.24559740.OutputStream._000232.root') as file:\n",
    "    pi0_data = file['EventTree'].arrays(library='ak')\n",
    "    \n",
    "with ur.open(data_path + 'pipm/user.angerami.24559744.OutputStream._000232.root') as file:\n",
    "    pipm_data = file['EventTree'].arrays(library='ak')\n",
    "    \n",
    "orig_pred = np.concatenate((ak.flatten(pipm_data['cluster_E']), \n",
    "                            ak.flatten(pi0_data['cluster_E']))).to_numpy()\n",
    "\n",
    "orig_target = np.concatenate((ak.flatten(pipm_data['cluster_ENG_CALIB_TOT']), \n",
    "                              ak.flatten(pi0_data['cluster_ENG_CALIB_TOT']))).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f6c24bb-3f8a-4278-93a6-9e33a5f1ae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 'log' # 'log', 'std', or 'max'\n",
    "\n",
    "if norm == 'log':\n",
    "    scaler = None\n",
    "elif norm == 'std':\n",
    "    scaler = StandardScaler()\n",
    "elif norm == 'max':\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "if scaler is not None:\n",
    "    sample = orig_target.reshape(-1, 1)\n",
    "    scaler.fit(sample)\n",
    "\n",
    "normalizer = (norm, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a421617d-662f-4a5c-a560-499b0267ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = False\n",
    "train = True\n",
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd5aae87-2505-4b09-9a0f-fc19b0e39c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 13:51:57.003691: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2023-06-13 13:51:57.005138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6915 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1b:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 4)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "garnet (GarNetStack)            (None, 16)           2976        input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           272         garnet[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            136         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "classification (Dense)          (None, 2)            18          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "regression (Dense)              (None, 1)            9           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 3,411\n",
      "Trainable params: 3,411\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if train:\n",
    "    K.clear_session()\n",
    "    model = GarNetModel()\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "092d59de-a158-4660-9ec1-e63bb01b86d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_val_split = 0.8\n",
    "batch_size = 64\n",
    "\n",
    "pi0_list = [[data_path + f'pi0/user.angerami.24559740.OutputStream._000{i:03d}.root', 1] \n",
    "            for i in list(range(11, 113)) + list(range(116, 432))]\n",
    "pipm_list = [[data_path + f'pipm/user.angerami.24559744.OutputStream._000{i:03d}.root', 0] \n",
    "             for i in list(range(11, 113)) + list(range(116, 432))]\n",
    "\n",
    "np.random.shuffle(pi0_list)\n",
    "np.random.shuffle(pipm_list)\n",
    "\n",
    "train_start = 0\n",
    "train_end = train_start + int(train_val_split*len(pi0_list))\n",
    "val_start = train_end\n",
    "val_end = len(pi0_list)\n",
    "train_file_list = (pi0_list[train_start:train_end], pipm_list[train_start:train_end])\n",
    "val_file_list = (pi0_list[val_start:val_end], pipm_list[val_start:val_end])\n",
    "\n",
    "test_file_list = ([[data_path + f'pi0/user.angerami.24559740.OutputStream._000{i:03d}.root', 1] for i in range(432, 464)],\n",
    "                  [[data_path + f'pipm/user.angerami.24559744.OutputStream._000{i:03d}.root', 0] for i in range(432, 464)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3490dc2f-c1c9-4623-81dd-aacfa247d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_generator = garnetDataGenerator(train_file_list, \n",
    "                                      cell_geo_path, \n",
    "                                      batch_size,\n",
    "                                      normalizer=normalizer,\n",
    "                                      name='garnet_' + normalizer[0],\n",
    "                                      labeled=True, \n",
    "                                      preprocess=preprocess, \n",
    "                                      output_dir=out_path + 'train/')\n",
    "\n",
    "if preprocess: cell_geo_path = train_generator.geo_dict\n",
    "\n",
    "validation_generator = garnetDataGenerator(val_file_list, \n",
    "                                           cell_geo_path,\n",
    "                                           int(batch_size*(1 - train_val_split)/train_val_split),\n",
    "                                           normalizer=normalizer,\n",
    "                                           name='garnet_' + normalizer[0],\n",
    "                                           labeled=True, \n",
    "                                           preprocess=preprocess, \n",
    "                                           output_dir=out_path + 'val/')\n",
    "\n",
    "test_generator = garnetDataGenerator(test_file_list,\n",
    "                                     cell_geo_path,\n",
    "                                     batch_size=20000,\n",
    "                                     normalizer=normalizer,\n",
    "                                     name='garnet_' + normalizer[0],\n",
    "                                     labeled=True,\n",
    "                                     preprocess=preprocess,\n",
    "                                     output_dir=out_path + 'test/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b967b6e-4753-496b-b86f-a6d7e7c90db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 13:52:02.172559: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100: [==================================================] 3200/3200\n",
      "72s - loss: 1.2408 - val loss: 0.7041\n",
      "Epoch 1/100: [==================================================] 3200/3200\n",
      "62s - loss: 0.6115 - val loss: 0.6114\n",
      "Epoch 2/100: [==================================================] 3200/3200\n",
      "58s - loss: 0.5391 - val loss: 0.5220\n",
      "Epoch 3/100: [==================================================] 3200/3200\n",
      "62s - loss: 0.5040 - val loss: 0.4719\n",
      "Epoch 4/100: [==================================================] 3200/3200\n",
      "65s - loss: 0.4810 - val loss: 0.4429\n",
      "Epoch 5/100: [==================================================] 3200/3200\n",
      "63s - loss: 0.4639 - val loss: 0.4454\n",
      "Epoch 6/100: [==================================================] 3200/3200\n",
      "64s - loss: 0.4579 - val loss: 0.4873\n",
      "Epoch 7/100: [==================================================] 3200/3200\n",
      "64s - loss: 0.4442 - val loss: 0.4528\n",
      "Epoch 8/100: [==================================================] 3200/3200\n",
      "64s - loss: 0.5144 - val loss: 0.5174\n",
      "Epoch 9/100: [==================================================] 3200/3200\n",
      "61s - loss: 0.4610 - val loss: 0.4540\n",
      "Epoch 10/100: [==================================================] 3200/3200\n",
      "58s - loss: 0.4334 - val loss: 0.4287\n",
      "Epoch 11/100: [==================================================] 3200/3200\n",
      "45s - loss: 0.4648 - val loss: 0.4137\n",
      "Epoch 12/100: [==================================================] 3200/3200\n",
      "50s - loss: 0.4185 - val loss: 0.4139\n",
      "Epoch 13/100: [==================================================] 3200/3200\n",
      "56s - loss: 0.4071 - val loss: 0.4017\n",
      "Epoch 14/100: [==================================================] 3200/3200\n",
      "63s - loss: 0.6825 - val loss: 0.4933\n",
      "Epoch 15/100: [==================================================] 3200/3200\n",
      "60s - loss: 0.4369 - val loss: 0.4179\n",
      "Epoch 16/100: [==================================================] 3200/3200\n",
      "61s - loss: 0.4195 - val loss: 0.4034\n",
      "Epoch 17/100: [==================================================] 3200/3200\n",
      "53s - loss: 0.4119 - val loss: 0.4123\n",
      "Epoch 18/100: [==================================================] 3200/3200\n",
      "53s - loss: 0.4011 - val loss: 0.3963\n",
      "Epoch 19/100: [==================================================] 3200/3200\n",
      "53s - loss: 0.4168 - val loss: 0.3933\n",
      "Epoch 20/100: [==================================================] 3200/3200\n",
      "58s - loss: 0.3951 - val loss: 0.3762\n",
      "Epoch 21/100: [==================================================] 3200/3200\n",
      "60s - loss: 0.3909 - val loss: 0.3831\n",
      "Epoch 22/100: [==================================================] 3200/3200\n",
      "56s - loss: 0.3823 - val loss: 0.3614\n",
      "Epoch 23/100: [==================================================] 3200/3200\n",
      "54s - loss: 0.4046 - val loss: 0.3825\n",
      "Epoch 24/100: [==================================================] 3200/3200\n",
      "51s - loss: 0.4303 - val loss: 0.3936\n",
      "Epoch 25/100: [==================================================] 3200/3200\n",
      "51s - loss: 0.3785 - val loss: 0.3561\n",
      "Epoch 26/100: [==================================================] 3200/3200\n",
      "46s - loss: 0.3793 - val loss: 0.3848\n",
      "Epoch 27/100: [==================================================] 3200/3200\n",
      "45s - loss: 0.3726 - val loss: 0.3631\n",
      "Epoch 28/100: [==================================================] 3200/3200\n",
      "49s - loss: 0.3589 - val loss: 0.3760\n",
      "Epoch 29/100: [==================================================] 3200/3200\n",
      "59s - loss: 0.3552 - val loss: 0.3549\n",
      "Epoch 30/100: [==================================================] 3200/3200\n",
      "56s - loss: 0.3514 - val loss: 0.3533\n",
      "Epoch 31/100: [==================================================] 3200/3200\n",
      "47s - loss: 0.3457 - val loss: 0.3620\n",
      "Epoch 32/100: [==================================================] 3200/3200\n",
      "42s - loss: 0.3449 - val loss: 0.3213\n",
      "Epoch 33/100: [==================================================] 3200/3200\n",
      "42s - loss: 0.3412 - val loss: 0.3389\n",
      "Epoch 34/100: [==================================================] 3200/3200\n",
      "48s - loss: 0.4359 - val loss: 0.3952\n",
      "Epoch 35/100: [==================================================] 3200/3200\n",
      "49s - loss: 0.3792 - val loss: 0.3587\n",
      "Epoch 36/100: [==================================================] 3200/3200\n",
      "47s - loss: 0.3453 - val loss: 0.3589\n",
      "Epoch 37/100: [==================================================] 3200/3200\n",
      "49s - loss: 0.3352 - val loss: 0.3272\n",
      "Epoch 38/100: [==================================================] 3200/3200\n",
      "45s - loss: 0.3284 - val loss: 0.2993\n",
      "Epoch 39/100: [==================================================] 3200/3200\n",
      "49s - loss: 0.3226 - val loss: 0.3302\n",
      "Epoch 40/100: [==================================================] 3200/3200\n",
      "41s - loss: 0.3199 - val loss: 0.3069\n",
      "Epoch 41/100: [==================================================] 3200/3200\n",
      "45s - loss: 0.3168 - val loss: 0.3084\n",
      "Epoch 42/100: [==================================================] 3200/3200\n",
      "51s - loss: 0.3140 - val loss: 0.3099\n",
      "Epoch 43/100: [==================================================] 3200/3200\n",
      "51s - loss: 0.3136 - val loss: 0.3186\n",
      "Epoch 44/100: [==================================================] 3200/3200\n",
      "47s - loss: 0.3053 - val loss: 0.3111\n",
      "Epoch 45/100: [==================================================] 3200/3200\n",
      "49s - loss: 0.3059 - val loss: 0.2972\n",
      "Epoch 46/100: [==================================================] 3200/3200\n",
      "47s - loss: 0.3128 - val loss: 0.3027\n",
      "Epoch 47/100: [==================================================] 3200/3200\n",
      "49s - loss: 0.3032 - val loss: 0.2882\n",
      "Epoch 48/100: [==================================================] 3200/3200\n",
      "48s - loss: 0.3002 - val loss: 0.2992\n",
      "Epoch 49/100: [==================================================] 3200/3200\n",
      "48s - loss: 0.3021 - val loss: 0.2865\n",
      "Epoch 50/100: [==================================================] 3200/3200\n",
      "48s - loss: 0.3028 - val loss: 0.2939\n",
      "Epoch 51/100: [==================================================] 3200/3200\n",
      "49s - loss: 0.2968 - val loss: 0.3054\n",
      "Epoch 52/100: [==================================================] 3200/3200\n",
      "45s - loss: 0.2932 - val loss: 0.3128\n",
      "Epoch 53/100: [==================================================] 3200/3200\n",
      "49s - loss: 0.2949 - val loss: 0.2800\n",
      "Epoch 54/100: [==================================================] 3200/3200\n",
      "48s - loss: 0.2873 - val loss: 0.3114\n",
      "Epoch 55/100: [==================================================] 3200/3200\n",
      "47s - loss: 0.2877 - val loss: 0.2879\n",
      "Epoch 56/100: [==================================================] 3200/3200\n",
      "48s - loss: 0.2828 - val loss: 0.2895\n",
      "Epoch 57/100: [==================================================] 3200/3200\n",
      "49s - loss: 0.2848 - val loss: 0.2832\n",
      "Epoch 58/100: [==================================================] 3200/3200\n",
      "47s - loss: 0.2817 - val loss: 0.2738\n",
      "Epoch 59/100: [==================================================] 3200/3200\n",
      "48s - loss: 0.2825 - val loss: 0.2768\n",
      "Epoch 60/100: [==================================================] 3200/3200\n",
      "48s - loss: 0.2834 - val loss: 0.2633\n",
      "Epoch 61/100: [==================================================] 3200/3200\n",
      "48s - loss: 0.2792 - val loss: 0.2777\n",
      "Epoch 62/100: [==================================================] 3200/3200\n",
      "47s - loss: 0.2749 - val loss: 0.2657\n",
      "Epoch 63/100: [==================================================] 3200/3200\n",
      "48s - loss: 0.2715 - val loss: 0.2702\n",
      "Epoch 64/100: [==================================================] 3200/3200\n",
      "47s - loss: 0.2704 - val loss: 0.2676\n",
      "Epoch 65/100: [==================================================] 3200/3200\n",
      "47s - loss: 0.2655 - val loss: 0.2772\n",
      "Epoch 66/100: [==================================================] 3200/3200\n",
      "48s - loss: 0.2706 - val loss: 0.2548\n",
      "Epoch 67/100: [==================================================] 3200/3200\n",
      "46s - loss: 0.2682 - val loss: 0.2648\n",
      "Epoch 68/100: [==================================================] 3200/3200\n",
      "50s - loss: 0.2689 - val loss: 0.2521\n",
      "Epoch 69/100: [==================================================] 3200/3200\n",
      "50s - loss: 0.2621 - val loss: 0.2612\n",
      "Epoch 70/100: [==================================================] 3200/3200\n",
      "47s - loss: 0.2637 - val loss: 0.2690\n",
      "Epoch 71/100: [==================================================] 3200/3200\n",
      "48s - loss: 0.2584 - val loss: 0.2573\n",
      "Epoch 72/100: [==================================================] 3200/3200\n",
      "48s - loss: 0.2589 - val loss: 0.2434\n",
      "Epoch 73/100: [==================================================] 3200/3200\n",
      "44s - loss: 0.2586 - val loss: 0.2568\n",
      "Epoch 74/100: [==================================================] 3200/3200\n",
      "47s - loss: 0.2557 - val loss: 0.2594\n",
      "Epoch 75/100: [================================================..] 3118/3200\r"
     ]
    }
   ],
   "source": [
    "if train:\n",
    "    \n",
    "    #def scheduler(epoch, lr):\n",
    "        #if epoch < 20:\n",
    "            #return lr\n",
    "        #else:\n",
    "            #return lr*tf.math.exp(-0.10)\n",
    "    #lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "    #def regression_loss(y_true, y_pred):\n",
    "        #return K.mean(K.square((y_true - y_pred) / (y_true + K.epsilon())), axis=-1)\n",
    "    regression_loss = keras.losses.MeanSquaredError()\n",
    "    classification_loss = keras.losses.BinaryCrossentropy()\n",
    "    \n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005)\n",
    "    losses = {'regression': regression_loss, 'classification': classification_loss}\n",
    "    loss_weights = {'regression': 0.90, 'classification': 0.10}\n",
    "    \n",
    "    def loss_fcn(y_true, y_pred):\n",
    "        return loss_weights['regression']*losses['regression'](y_true[:,2:3], y_pred[:,2:3]) + \\\n",
    "               loss_weights['classification']*losses['classification'](y_true[:,0], y_pred[:,0])\n",
    "        \n",
    "    model.compile(optimizer=optimizer, loss=losses, loss_weights=loss_weights, metrics=['accuracy'])\n",
    "    \n",
    "    callbacks = [PrinterCallback(), \n",
    "                 keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=5, verbose=1),\n",
    "                 keras.callbacks.EarlyStopping(verbose=1, patience=10)]\n",
    "    \n",
    "    history = model.fit(train_generator.generator(), \n",
    "                        validation_data=validation_generator.generator(),\n",
    "                        steps_per_epoch=3200,\n",
    "                        validation_steps=800,\n",
    "                        shuffle=True,\n",
    "                        epochs=100,\n",
    "                        callbacks=[PrinterCallback()],\n",
    "                        verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849a1a6c-66e1-413c-a999-5853d612acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save:\n",
    "    model.save(out_path + 'models/GarNet_' + normalizer[0])\n",
    "\n",
    "    with open(out_path + 'models/GarNet_' + normalizer[0] + '/history.pickle', 'wb') as handle:\n",
    "        pickle.dump(history.history, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    with open(out_path + 'models/GarNet_' + normalizer[0] + '/scaler.pickle', 'wb') as handle:\n",
    "        pickle.dump(scaler, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b71db0-1769-4019-99e9-c119c6f48c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = tf.keras.models.load_model(out_path + 'models/GarNet_' + normalizer[0], \n",
    "                                   custom_objects={\"GarNetModel\": GarNetModel}, compile=False)\n",
    "\n",
    "with open(out_path + 'models/GarNet_' + normalizer[0] + '/history.pickle', \"rb\") as file:\n",
    "    history = pickle.load(file)\n",
    "    \n",
    "with open(out_path + 'models/GarNet_' + normalizer[0] + '/scaler.pickle', \"rb\") as file:\n",
    "    scaler = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bba9ae-cd7e-446d-a779-097776f2b15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(test_generator.generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a7f36c-1411-40f6-901f-86bfd70ee886",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_curve = Plotter(training, history=history, metrics=['loss', 'classification_loss', 'regression_loss'], scale='log')\n",
    "loss_curve.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1d0a8-75fa-4027-8f4d-9a4ed87841ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_curve = Plotter(training, history=history, metrics=['regression_accuracy'])\n",
    "accuracy_curve.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48c2e1-c86e-415d-9bae-a35722d6a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC = Plotter(roc, preds=[model.predict(x)[0][:,0]], targets=[y['classification'][:,0]], labels=[''])\n",
    "ROC.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381290cf-0fad-4f47-bec3-ed4a589e92cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if normalizer[0] == 'log':\n",
    "    fit_pred = np.exp(model.predict(x)[-1]).reshape(-1,)\n",
    "    fit_target = np.exp(y['regression']).reshape(-1,)\n",
    "else:\n",
    "    scaler = normalizer[1]\n",
    "    fit_pred = scaler.inverse_transform(model.predict(x)[-1]).reshape(-1,)\n",
    "    fit_target = scaler.inverse_transform(np.reshape(y['regression'], (-1, 1))).reshape(-1,)\n",
    "\n",
    "reg = Plotter(regResponse, \n",
    "              pred=fit_pred, \n",
    "              target=fit_target,\n",
    "              stat=['median'])\n",
    "reg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df041e-6986-438e-bc68-8d75136f748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Plotter(regResponseOverlay,\n",
    "              preds=[orig_pred, fit_pred],\n",
    "              targets=[orig_target, fit_target],\n",
    "              labels=['Pre-Fit', 'Post-Fit'],\n",
    "              stat=['mean', 'stdmean'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
